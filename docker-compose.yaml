version: '3.8'

services:
  # 1. ZOOKEEPER
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: "-Xmx256m -Xms256m"
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 512m

  # 2. KAFKA
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on: [zookeeper]
    ports: ["9092:9092"]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_HEAP_OPTS: "-Xmx512m -Xms512m"
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 1g
    volumes:
      - kafka_data:/bitnami/kafka      

  # 3. MINIO
  minio:
    image: minio/minio:latest
    container_name: minio
    ports: ["9000:9000", "9001:9001"]
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: admin12345
    command: server /data --console-address ":9001"
    volumes:
      - ./minio_data:/data
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 1g

  # 4. PRODUCER (BINANCE DATA)
  producer:
    build: .
    container_name: binance_producer
    restart: always
    depends_on: [kafka]
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    command: python producer.py
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 512m

  # 5. SPARK CONSUMER (BRONZE LAYER)
  spark-consumer:
    build: .
    container_name: spark-consumer
    # --- Ä°ÅžTE EKSÄ°K OLAN SATIR BURADA ---
    command: python consumer_lake.py
    # ------------------------------------
    restart: always 
    depends_on: [kafka, minio]
    environment:
      - SPARK_DRIVER_MEMORY=1g
      - SPARK_EXECUTOR_MEMORY=1g
    volumes:
      - ./checkpoints:/app/checkpoints
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 2g

  # 6. SPARK SILVER (PROCESSING LAYER)
  spark-silver:
    build: .
    container_name: spark-silver
    restart: always # <-- DeÄŸiÅŸti: Sistem sÃ¼rekli ayakta kalsÄ±n
    depends_on: [minio, spark-consumer]
    environment:
      - SPARK_MASTER=local[*]
      - SPARK_DRIVER_MEMORY=1500m
      - SPARK_EXECUTOR_MEMORY=1500m
    command: python process_silver.py
    volumes:
      - ./checkpoints_silver:/app/checkpoints_silver
      - ./:/app 
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 3g
          cpus: '2.0'

  # ---------------------------------------------------------
  # ðŸ†• 7. ML TRAINER (AIRFLOW YERÄ°NE GELEN BEKÃ‡Ä°)
  # ---------------------------------------------------------
  ml-trainer:
    build: .
    container_name: ml-trainer
    restart: always
    depends_on: [spark-silver]
    # Airflow yerine senin yazdÄ±ÄŸÄ±n bekÃ§i kodunu Ã§alÄ±ÅŸtÄ±rÄ±r
    command: python ml_watcher.py  
    volumes:
      - ./:/app
      - ./models:/app/models
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow_server:5000
      - MINIO_ENDPOINT=http://minio:9000
    networks: [data-network]

  # 8. DASHBOARD
  dashboard:
    build: .
    container_name: dashboard
    command: streamlit run dashboard_app/Home.py --server.port 8501 --server.address 0.0.0.0
    ports:
      - "8501:8501"
    depends_on:
      - postgres
      - minio
      - spark-silver
      - mlflow         
    env_file:          
      - .env
    environment:
      # Airflow deÄŸiÅŸkenlerini kaldÄ±rdÄ±k, gerek kalmadÄ±
      - MLFLOW_INTERNAL_URI=${MLFLOW_INTERNAL_URI}
      - MLFLOW_EXTERNAL_UI=${MLFLOW_EXTERNAL_UI}
    networks:
      - data-network
    deploy:
      resources:
        limits:
          memory: 1g
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./dashboard_app:/app/dashboard_app
      
  # 9. POSTGRES
  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: market_db
    ports: [ "5432:5432" ]
    networks: [ data-network ]
    deploy:
      resources:
        limits:
          memory: 1g
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # 10. DBT
  dbt:
    build: ./dbt_project
    container_name: dbt_transformer
    command: >
      sh -c "tail -f /dev/null"
    depends_on:
      - postgres
    volumes:
      - ./dbt_project:/usr/app
    networks:
      - data-network
    deploy:
      resources:
        limits:
          memory: 512m

  # 11. API GATEWAY
  api-gateway:
    build: .
    container_name: api_gateway
    command: uvicorn ingestion_api:app --host 0.0.0.0 --port 8000
    ports:
      - "8000:8000"
    depends_on: [kafka]
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 256m

  # 12. CADVISOR
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    ports:
      - "8090:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    networks:
      - data-network

  # 13. PROMETHEUS
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    depends_on:
      - cadvisor
    networks:
      - data-network

  # 14. GRAFANA
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus
    networks:
      - data-network
    volumes:
      - grafana_data:/var/lib/grafana
  
  # 15. MLFLOW SERVER
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.7.1
    container_name: mlflow_server
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=admin12345
    command: >
      mlflow server 
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root s3://market-data/mlflow-artifacts
      --host 0.0.0.0
    networks:
      - data-network
    depends_on:
      - minio

  # 16. METABASE
  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    ports:
      - "3005:3000"
    networks:
      - data-network
    restart: always
  
 
  # 6. KAFKA CONNECT:
  kafka-connect:
    build:
      context: .
      dockerfile: Dockerfile.connect
    container_name: kafka-connect
    ports:
      - "8083:8083"
    depends_on:
      - kafka
      - zookeeper
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: "compose-connect-group"
      CONNECT_CONFIG_STORAGE_TOPIC: "docker-connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "docker-connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "docker-connect-status"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_LISTENERS: "HTTP://0.0.0.0:8083"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      KAFKA_HEAP_OPTS: "-Xms512M -Xmx1G"
    networks:
      - data-network
   
  # 7. KAFKA CONNECT UI (GÃ¶rsel YÃ¶netim Paneli)
  kafka-connect-ui:
    image: landoop/kafka-connect-ui:0.9.7
    container_name: kafka-connect-ui
    ports:
      - "8003:8000"
    environment:
      - "CONNECT_URL=http://kafka-connect:8083"
      - "PROXY=true"
    depends_on:
      - kafka-connect
    networks:
      - data-network

  # 17. KAFDROP (Kafka UI)
  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    restart: always
    ports:
      - "9010:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092"
      JVM_OPTS: "-Xms32M -Xmx64M"
      SERVER_SERVLET_CONTEXT_PATH: "/"
    depends_on:
      - kafka
    networks:
      - data-network


networks:
  data-network:
    driver: bridge

volumes:
  grafana_data:
  kafka_data:
  postgres_data: