version: '3.8'

services:
  # 1. ZOOKEEPER
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: "-Xmx256m -Xms256m"
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 512m

  # 2. KAFKA
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on: [zookeeper]
    ports: ["9092:9092"]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_HEAP_OPTS: "-Xmx512m -Xms512m"
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 1g
<<<<<<< HEAD
    volumes:
      - kafka_data:/bitnami/kafka      
=======
>>>>>>> cda2fd09ebf927cfc7e32d5c77b558c212d4f57c

  # 3. MINIO
  minio:
    image: minio/minio:latest
    container_name: minio
    ports: ["9000:9000", "9001:9001"]
    environment:
<<<<<<< HEAD
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: admin12345
    command: server /data --console-address ":9001"
    volumes:
      - ./minio_data:/data
=======
      MINIO_ROOT_USER: admin          # <-- Python koduyla eşitledik
      MINIO_ROOT_PASSWORD: admin12345 # <-- Python koduyla eşitledik
    command: server /data --console-address ":9001"
    volumes:
      - ./minio_data:/data  # <-- DİKKAT: Bu klasörü aşağıda sileceğiz!
>>>>>>> cda2fd09ebf927cfc7e32d5c77b558c212d4f57c
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 1g
<<<<<<< HEAD

  # 4. PRODUCER (BİNANCE DATA)
  producer:
    build: .
    container_name: binance_producer  # <-- GÜNCELLENDİ: Sabit isim verdik
=======
  # 4. PRODUCER
  producer:
    build: .
    container_name: producer
>>>>>>> cda2fd09ebf927cfc7e32d5c77b558c212d4f57c
    restart: always
    depends_on: [kafka]
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    command: python producer.py
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 512m

  # 5. SPARK CONSUMER
  spark-consumer:
    build: .
    container_name: spark-consumer
    restart: on-failure
    depends_on: [kafka, minio]
    environment:
      - SPARK_MASTER=local[*]
      - SPARK_DRIVER_MEMORY=512m
      - SPARK_EXECUTOR_MEMORY=512m
    volumes:
      - ./checkpoints:/app/checkpoints
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 2g

  # 6. SPARK SILVER
  spark-silver:
    build: .
    container_name: spark-silver
    restart: on-failure
    depends_on: [minio, spark-consumer]
    environment:
      - SPARK_MASTER=local[*]
      - SPARK_DRIVER_MEMORY=1500m
      - SPARK_EXECUTOR_MEMORY=1500m
    command: python process_silver.py
    volumes:
      - ./checkpoints_silver:/app/checkpoints_silver
      - ./:/app 
    networks: [data-network]
    deploy:
      resources:
        limits:
<<<<<<< HEAD
          memory: 3g
          cpus: '2.0'
=======
          memory: 4g
>>>>>>> cda2fd09ebf927cfc7e32d5c77b558c212d4f57c

  # 7. DASHBOARD
  dashboard:
    build: .
    container_name: dashboard
<<<<<<< HEAD
    command: streamlit run dashboard_app/Home.py --server.port 8501 --server.address 0.0.0.0
=======
    command: streamlit run dashboard.py --server.port 8501 --server.address 0.0.0.0
>>>>>>> cda2fd09ebf927cfc7e32d5c77b558c212d4f57c
    ports:
      - "8501:8501"
    depends_on:
      - postgres
      - minio
      - spark-silver
<<<<<<< HEAD
      - airflow        
      - mlflow         # <--- DÜZELTİLEN KISIM (mlflow_server DEĞİL, mlflow OLACAK)
    env_file:          
      - .env
    environment:
      - AIRFLOW_INTERNAL_API=${AIRFLOW_INTERNAL_API}
      - AIRFLOW_EXTERNAL_UI=${AIRFLOW_EXTERNAL_UI}
      - MLFLOW_INTERNAL_URI=${MLFLOW_INTERNAL_URI}
      - MLFLOW_EXTERNAL_UI=${MLFLOW_EXTERNAL_UI}
=======
    environment:
      - MINIO_URL=http://minio:9000
      - POSTGRES_HOST=postgres
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092 
>>>>>>> cda2fd09ebf927cfc7e32d5c77b558c212d4f57c
    networks:
      - data-network
    deploy:
      resources:
        limits:
          memory: 1g
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
<<<<<<< HEAD
      - ./dashboard_app:/app/dashboard_app
=======
      - ./dashboard.py:/app/dashboard.py 

>>>>>>> cda2fd09ebf927cfc7e32d5c77b558c212d4f57c
  # 8. POSTGRES
  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: market_db
    ports: [ "5432:5432" ]
    networks: [ data-network ]
    deploy:
      resources:
        limits:
          memory: 1g
<<<<<<< HEAD
    volumes:
      - postgres_data:/var/lib/postgresql/data
=======
>>>>>>> cda2fd09ebf927cfc7e32d5c77b558c212d4f57c

  # 9. DBT
  dbt:
    build: ./dbt_project
    container_name: dbt_transformer
    command: >
      sh -c "tail -f /dev/null"
    depends_on:
      - postgres
    volumes:
      - ./dbt_project:/usr/app
    networks:
      - data-network
    deploy:
      resources:
        limits:
          memory: 512m

  # 10. API GATEWAY
  api-gateway:
    build: .
    container_name: api_gateway
    command: uvicorn ingestion_api:app --host 0.0.0.0 --port 8000
    ports:
      - "8000:8000"
    depends_on: [kafka]
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    networks: [data-network]
    deploy:
      resources:
        limits:
          memory: 256m

  # 11. CADVISOR
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    ports:
      - "8090:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    networks:
      - data-network

  # 12. PROMETHEUS
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    depends_on:
      - cadvisor
    networks:
      - data-network

  # 13. GRAFANA
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus
    networks:
      - data-network
    volumes:
      - grafana_data:/var/lib/grafana
  
  # 14. MLFLOW SERVER
<<<<<<< HEAD
=======
  # 14. MLFLOW SERVER
>>>>>>> cda2fd09ebf927cfc7e32d5c77b558c212d4f57c
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.7.1
    container_name: mlflow_server
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=admin12345
    command: >
      mlflow server 
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root s3://market-data/mlflow-artifacts
      --host 0.0.0.0
    networks:
      - data-network
    depends_on:
      - minio

  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    ports:
      - "3005:3000"
    networks:
      - data-network
    restart: always
<<<<<<< HEAD

=======
>>>>>>> cda2fd09ebf927cfc7e32d5c77b558c212d4f57c
  # 15. AIRFLOW
  airflow:
    build: 
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow
    user: "${AIRFLOW_UID:-50000}:0"
    ports:
      - "8081:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://admin:admin@postgres/market_db
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - postgres
    command: >
      bash -c "
      echo 'Veritabaninin hazir olmasi bekleniyor...' &&
      sleep 20 &&
      airflow db migrate &&
      airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin || true &&
      (airflow webserver & airflow scheduler)
      "
    networks:
      - data-network

networks:
  data-network:
    driver: bridge

volumes:
<<<<<<< HEAD
  grafana_data:
  kafka_data:
  postgres_data:
=======
  grafana_data:
>>>>>>> cda2fd09ebf927cfc7e32d5c77b558c212d4f57c
