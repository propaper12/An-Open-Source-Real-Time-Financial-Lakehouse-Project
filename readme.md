# Enterprise Real-Time Lakehouse & MLOps Platform

Bu platform; Binance WebSocket ve Ã¶zel API kanallarÄ±ndan gelen canlÄ± market verilerini iÅŸleyen, **Delta Lake** mimarisi Ã¼zerinde depolayan, **Spark MLlib** ile yapay zeka modelleri eÄŸiten ve **dbt** ile profesyonel analitik katmanlar oluÅŸturan uÃ§tan uca bir veri mÃ¼hendisliÄŸi iskeletidir.
<img width="8192" height="1912" alt="Untitled diagram-2026-01-12-172902" src="https://github.com/user-attachments/assets/e2975ffb-1d66-4144-a29a-80cd2f462182" />

----------

## ğŸ—ï¸ Mimari TasarÄ±m (Architecture)

Sistem, verinin ham halden alÄ±narak anlamlÄ± iÅŸ zekasÄ± raporlarÄ±na dÃ¶nÃ¼ÅŸmesine kadar 5 ana katmandan oluÅŸur:




Proje, her biri belirli bir amaca hizmet eden modÃ¼ler bir yapÄ± Ã¼zerine inÅŸa edilmiÅŸtir. AÅŸaÄŸÄ±da, sistemin omurgasÄ±nÄ± oluÅŸturan dosyalarÄ±n detaylÄ± aÃ§Ä±klamalarÄ±nÄ± bulabilirsiniz:

#### ğŸ“¥ Veri GiriÅŸi ve API (Ingestion)

-   ğŸš€ **`producer.py`**: Binance WebSocket API'sine baÄŸlanarak canlÄ± piyasa verilerini (Trade) yakalar ve **Apache Kafka**'ya "raw-trades" topic'i Ã¼zerinden asenkron olarak basÄ±r.
    
-   âš¡ **`ingestion_api.py`**: FastAPI tabanlÄ± bir gateway'dir. DÄ±ÅŸ kurumsal kaynaklardan (Ã¶rneÄŸin Tesla) gelen verileri kabul eder ve Kafka'ya yÃ¶nlendirir.
    
-   ğŸ¢ **`fake_company.py`**: Sistemi test etmek iÃ§in geliÅŸtirilmiÅŸ bir simÃ¼latÃ¶rdÃ¼r. Kendi ÅŸirket verileriniz varmÄ±ÅŸ gibi FastAPI Ã¼zerinden sisteme veri gÃ¶nderir.
    

#### âš™ï¸ Veri Ä°ÅŸleme ve Storage (Processing & Lakehouse)

-   ğŸŒŠ **`process_silver.py`**: Sistemin ana motoru (Spark Streaming). Kafka'dan veriyi okur, ÅŸema doÄŸrulamasÄ± yapar, **Spark ML** modellerini kullanarak "In-flight" tahminleme yapar ve sonuÃ§larÄ± **Delta Lake Silver** katmanÄ±na yazar.
    
-   ğŸ¥‰ **`consumer_lake.py`**: Kafka'dan gelen ham verileri hiÃ§bir deÄŸiÅŸikliÄŸe uÄŸratmadan **Delta Lake Bronze** katmanÄ±na (Raw Data) yazar; veri geÃ§miÅŸinin korunmasÄ±nÄ± (Audit) saÄŸlar.
    
-   ğŸ—ï¸ **`dbt_project/`**: Verinin Silver'dan Gold katmanÄ±na (Analitik katman) dÃ¶nÃ¼ÅŸÃ¼mÃ¼ iÃ§in gerekli SQL modellerini iÃ§erir. Veri temizleme ve aggregation iÅŸlemleri burada dÃ¶ner.
    

#### ğŸ§  MLOps ve Otomasyon (Orchestration)

-   ğŸ§ª **`train_model.py`**: Delta Lake'deki geÃ§miÅŸ verileri kullanarak model eÄŸitir. **MLflow** ile entegre Ã§alÄ±ÅŸarak her eÄŸitimdeki metrikleri (RMSE, MAE vb.) ve model dosyalarÄ±nÄ± kayÄ±t altÄ±na alÄ±r.
    
-   ğŸ“… **`dags/`**: **Apache Airflow** tarafÄ±ndan kullanÄ±lan DAG dosyalarÄ±dÄ±r. Modellerin haftalÄ±k yeniden eÄŸitilmesi veya dbt dÃ¶nÃ¼ÅŸÃ¼mlerinin periyodik Ã§alÄ±ÅŸmasÄ± burada planlanÄ±r.
    

#### ğŸ–¥ï¸ ArayÃ¼z ve AltyapÄ± (UI & DevOps)

-   ğŸ“Š **`dashboard.py`**: **Streamlit** ile geliÅŸtirilmiÅŸ komuta merkezidir. CanlÄ± fiyat akÄ±ÅŸÄ±nÄ±, yapay zeka tahminlerini ve sistem saÄŸlÄ±ÄŸÄ±nÄ± gÃ¶rselleÅŸtirir.
    
-   ğŸ³ **`docker-compose.yaml`**: TÃ¼m ekosistemi (Kafka, Spark, Airflow, MinIO, Postgres vb.) birbirine baÄŸlÄ± ve izole bir ÅŸekilde ayaÄŸa kaldÄ±ran ana orkestrasyon dosyasÄ±dÄ±r.
    
-   ğŸ“¦ **`Dockerfile` / `Dockerfile.spark`**: Spark ve API gibi Ã¶zel servislerin Ã§alÄ±ÅŸmasÄ± iÃ§in gerekli kÃ¼tÃ¼phane ve baÄŸÄ±mlÄ±lÄ±klarÄ±n (Python, Java, Delta Jar) tanÄ±mlandÄ±ÄŸÄ± paketleme dosyalarÄ±dÄ±r.
    
-   ğŸ“‘ **`requirements.txt`**: Projenin Ã§alÄ±ÅŸmasÄ± iÃ§in gerekli tÃ¼m Python kÃ¼tÃ¼phanelerinin (PySpark, Kafka-Python, Delta-Spark, FastAPI) listesidir.
----------
## ğŸ› ï¸ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma Rehberi
### 1. Sistemi BaÅŸlatma

Docker konteynerlerini (Kafka, Spark, Airflow, Postgres, MinIO vb.) derler ve arka planda Ã§alÄ±ÅŸtÄ±rÄ±r:
Bash
```
docker-compose up -d --build
```
### 2. Åirket Veri SimÃ¼lasyonunu BaÅŸlatma

Ã–zel ÅŸirket akÄ±ÅŸÄ±nÄ± tetiklemek (Tesla vb.) ve API'yi test etmek iÃ§in:
Bash
```
python fake_company.py
```

### 3. AI Modellerini EÄŸitme

Sistemde yeterli veri biriktikten sonra modelleri eÄŸitmek ve MLflow'a kaydetmek iÃ§in:
Bash
```
docker exec spark-silver python train_model.py
```

### 4. dbt DÃ¶nÃ¼ÅŸÃ¼mlerini Ã‡alÄ±ÅŸtÄ±rma
Verileri PostgreSQL Gold katmanÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmek ve analitik hazÄ±rlÄ±k yapmak iÃ§in:
Bash
```
docker exec dbt_transformer dbt run
```

----------

## ğŸ“Š Ä°zleme ve Analiz Panelleri

**Servis Port KullanÄ±m AmacÄ±**

**Streamlit Dashboard**:
`http://localhost:8501` CanlÄ± Teknik Analiz & AI Tahmin BandÄ±.

**Metabase BI**
`http://localhost:3005/`Kurumsal SQL Raporlama & Business Intelligence.

**MLflow**
`http://localhost:5000/`Model Versiyonlama ve Performans Takibi.

**Airflow UI**
`http://localhost:8081`Pipeline Otomasyonu ve DAG YÃ¶netimi.

**MinIO Console**
`http://localhost:9001`S3 Lakehouse Veri GÃ¶rÃ¼ntÃ¼leyici.

**Grafana**
`http://localhost:3001/`Sistem SaÄŸlÄ±ÄŸÄ± ve AltyapÄ± Ä°zleme.

**CAdvisor**
`http://localhost:8090/containers/`

**API Docs**
`http://localhost:8000/docs`FastAPI Swagger DokÃ¼mantasyonu.

----------

## ğŸ‘¨â€ğŸ’» GeliÅŸtirici NotlarÄ± (Ops & Debug)

### **Kodlarda deÄŸiÅŸiklik yaptÄ±ÄŸÄ±nda tÃ¼m sistemi kapatÄ±p aÃ§mana gerek yok.**

Ã¶rnek:Konteyneri durdurmadan dashboard kodunu gÃ¼ncellemek iÃ§in:
Bash
```
docker cp dashboard.py dashboard:/app/dashboard.py
docker restart dashboard
```
### **KÃ¶klÃ¼ DeÄŸiÅŸiklik veya KÃ¼tÃ¼phane Eklediysen (Dockerfile).**
Bash
```
docker-compose up -d --build
```

### **Veri DoÄŸrulama (SQL)**

Verilerin doÄŸru yazÄ±ldÄ±ÄŸÄ±nÄ± PostgreSQL iÃ§inden kontrol etmek iÃ§in:
Bash
```
docker exec -it postgres psql -U admin -d market_db -c "SELECT * FROM crypto_prices LIMIT 10;"
```

### **Roadmap & Gelecek PlanlarÄ±**

-   [ ] GitHub Actions ile CI/CD Pipeline Entegrasyonu.
    
-   [ ] Great Expectations ile Data Quality Checks.
    
-   [ ] Slack/Telegram Ã¼zerinden hata bildirimleri.
    

----------

## ğŸ¤ KatkÄ±da Bulunun (Contributing)

Bu proje bir **YBS Ã¶ÄŸrencisi** tarafÄ±ndan geliÅŸtirilmiÅŸ aÃ§Ä±k kaynaklÄ± bir framework'tÃ¼r. Her tÃ¼rlÃ¼ katkÄ±ya, fikre ve PR'a aÃ§Ä±ktÄ±r.

-   **GeliÅŸtirici:** Ã–mer Ã‡akan
    
-   **LinkedIn:** [Profil Linkini Buraya YapÄ±ÅŸtÄ±r]
    
-   **Destek:** Proje size yardÄ±mcÄ± olduysa bir â­ bÄ±rakmayÄ± unutmayÄ±n!
- ### 3. KatÄ±lÄ±mcÄ±lara Ã–zel Kod TalimatÄ±

Kendi branch'inizi aÃ§Ä±n, ama benim `main`'ime dokunmayÄ±n."

Bash
```
# 1. Ã–nce projeyi yerele indir
git clone https://github.com/propaper12/An-Open-Source-Real-Time-Financial-Lakehouse-Project.git

# 2. Kendi adÄ±nÄ±za veya Ã¶zelliÄŸinize gÃ¶re yeni bir branch aÃ§Ä±n
git checkout -b dev/herhangi_isim

# 3. GeliÅŸtirmenizi yapÄ±n ve sadece bu branch'e pushlayÄ±n
git push origin dev/herhangi_isim
```
