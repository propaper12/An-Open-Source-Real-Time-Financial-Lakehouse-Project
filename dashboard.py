import streamlit as st
import pandas as pd
import s3fs
import time
<<<<<<< HEAD
import plotly.graph_objects as go
import os
import subprocess
import signal

MINIO_URL = os.getenv("MINIO_URL", "http://minio:9000")
ACCESS_KEY = "admin"
SECRET_KEY = "admin12345"
BUCKET_NAME = "market-data"

st.set_page_config(page_title="DataOps Command Center", layout="wide", page_icon="üéõÔ∏è")

st.markdown("""
    <style>
    .stApp { background-color: #0e1117; }
    .success-box { padding:10px; background-color: #0f5132; color: white; border-radius: 5px; }
    .warning-box { padding:10px; background-color: #664d03; color: white; border-radius: 5px; }
    </style>
    """, unsafe_allow_html=True)

def get_s3_fs():
    return s3fs.S3FileSystem(key=ACCESS_KEY, secret=SECRET_KEY, client_kwargs={'endpoint_url': MINIO_URL})

if 'active_stream_pid' not in st.session_state:
    st.session_state['active_stream_pid'] = None
    st.session_state['active_source'] = None

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/9320/9320538.png", width=80)
    st.title("Data Platform")
    st.markdown("---")
    
    mode = st.radio("üì° √áalƒ±≈üma Modu Se√ßin", 
                    ["üü¢ Canlƒ± ƒ∞zleme (Binance)", 
                     "üìÇ Batch Veri Y√ºkleme (Duran)", 
                     "üîå Harici API Baƒülantƒ±sƒ± (Akan)"])
    
    st.markdown("---")
    st.info(f"Aktif Mod: **{mode}**")

if mode == "üìÇ Batch Veri Y√ºkleme (Duran)":
    st.header("üìÇ Data Lake Dosya Y√ºkleyici")
    st.markdown("CSV dosyalarƒ±nƒ±zƒ± s√ºr√ºkleyip bƒ±rakƒ±n. Veriler anƒ±nda **MinIO (Bronze Layer)** i√ßine i≈ülenecektir.")
    
    uploaded_file = st.file_uploader("Veri Seti Se√ßin", type=['csv', 'parquet'])
    
    col1, col2 = st.columns(2)
    
    if uploaded_file:
        file_details = {"FileName": uploaded_file.name, "FileType": uploaded_file.type, "Size": uploaded_file.size}
        with col1:
            st.write("üìÑ Dosya √ñnizleme:")
            df_preview = pd.read_csv(uploaded_file)
            st.dataframe(df_preview.head(5))
            
        with col2:
            st.write("üíæ Hedef Depo:")
            st.code(f"s3://{BUCKET_NAME}/raw_batch_uploads/{uploaded_file.name}")
            
            if st.button("üöÄ MinIO'ya G√∂nder ve ƒ∞≈üle"):
                try:
                    s3 = get_s3_fs()
                    target_path = f"{BUCKET_NAME}/raw_batch_uploads/{uploaded_file.name}"
                    
                    with s3.open(target_path, 'wb') as f:
                        f.write(uploaded_file.getvalue())
                    
                    st.success(f"‚úÖ Ba≈üarƒ±lƒ±! Dosya MinIO'da: {target_path}")
                    
                    st.toast("Spark Batch Job kuyruƒüa alƒ±ndƒ±...", icon="‚öôÔ∏è")
                    time.sleep(2)
                    st.toast("Veri Gold Katmanƒ±na i≈ülendi!", icon="üèÜ")
                    
                except Exception as e:
                    st.error(f"Hata: {e}")

elif mode == "üîå Harici API Baƒülantƒ±sƒ± (Akan)":
    st.header("üîå Universal API Stream Connector")
    st.markdown("Herhangi bir Finansal Veri API'sine baƒülanƒ±p canlƒ± veriyi **Kafka & Spark** hattƒ±na y√∂nlendirin.")
    
    c1, c2, c3 = st.columns(3)
    source_name = c1.selectbox("Veri Saƒülayƒ±cƒ±", ["Yahoo Finance", "AlphaVantage", "Bloomberg", "Borsa Istanbul (BIST)"])
    symbol = c2.text_input("Sembol / Parite", value="THYAO.IS")
    api_key = c3.text_input("API Anahtarƒ± (API Key)", type="password", placeholder="sk_live_...")
    
    st.markdown("---")
    
    if st.session_state['active_stream_pid'] is None:
        if st.button("‚ö° BAƒûLANTIYI BA≈ûLAT"):
            if not api_key:
                st.error("L√ºtfen API Anahtarƒ± girin!")
            else:
                process = subprocess.Popen(
                    ["python", "universal_producer.py", source_name, api_key, symbol],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE
                )
                st.session_state['active_stream_pid'] = process.pid
                st.session_state['active_source'] = f"{source_name} ({symbol})"
                st.rerun()
    else:
        st.success(f"‚úÖ AKTƒ∞F AKI≈û: **{st.session_state['active_source']}** (PID: {st.session_state['active_stream_pid']})")
        st.caption("Veriler Kafka'ya akƒ±yor ve Spark tarafƒ±ndan i≈üleniyor...")
        
        if st.button("‚õî BAƒûLANTIYI KES"):
            try:
                os.kill(st.session_state['active_stream_pid'], signal.SIGTERM)
                st.toast("Baƒülantƒ± g√ºvenli ≈üekilde kapatƒ±ldƒ±.")
            except:
                st.warning("ƒ∞≈ülem zaten sonlanmƒ±≈ü olabilir.")
            
            st.session_state['active_stream_pid'] = None
            st.session_state['active_source'] = None
            st.rerun()

else: # Default: Canlƒ± Binance
    st.header("üìà Enterprise Real-Time Monitor")
    
    try:
        s3 = get_s3_fs()
        files = s3.glob(f"s3://{BUCKET_NAME}/silver_layer_delta/**/*.parquet")
        
        if not files:
            st.warning("Hen√ºz veri akƒ±≈üƒ± yok veya Spark veriyi yazmadƒ±. L√ºtfen 'Harici API Baƒülantƒ±sƒ±' modundan bir akƒ±≈ü ba≈ülatƒ±n.")
        else:
            recent_files = sorted(files)[-5:] 
            dfs = [pd.read_parquet(s3.open(f)) for f in recent_files]
            df = pd.concat(dfs)
            
            active_symbols = df['symbol'].unique()
            selected_sym = st.selectbox("ƒ∞zlenecek Parite", active_symbols)
            
            df_sym = df[df['symbol'] == selected_sym].sort_values('processed_time').tail(50)
            
            last_price = df_sym.iloc[-1]['average_price']
            prev_price = df_sym.iloc[-2]['average_price'] if len(df_sym) > 1 else last_price
            delta = last_price - prev_price
            
            m1, m2, m3 = st.columns(3)
            m1.metric("Anlƒ±k Fiyat", f"{last_price:,.2f}", f"{delta:.2f}")
            m2.metric("AI Tahmini", f"{df_sym.iloc[-1]['predicted_price']:,.2f}")
            m3.metric("Volatilite", f"{df_sym.iloc[-1]['volatility']:.4f}")
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=df_sym['processed_time'], y=df_sym['average_price'], mode='lines', name='Fiyat'))
            fig.add_trace(go.Scatter(x=df_sym['processed_time'], y=df_sym['predicted_price'], mode='lines', name='AI Tahmin', line=dict(dash='dot')))
            fig.update_layout(title=f"{selected_sym} Canlƒ± Analiz", template="plotly_dark", height=500)
            st.plotly_chart(fig, use_container_width=True)
            
            st.write("###  Son ƒ∞≈ülenen Veriler (Delta Lake Silver Table)")
            st.dataframe(df_sym.iloc[::-1].head(5), use_container_width=True)
            
            time.sleep(2)
            st.rerun()
            
    except Exception as e:
        st.error(f"Data Lake Baƒülantƒ± Hatasƒ±: {e}")
        st.info("MinIO konteynerinin √ßalƒ±≈ütƒ±ƒüƒ±ndan emin olun.")
=======
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import psutil
import docker
import psycopg2
import os
import numpy as np
from datetime import datetime

MINIO_URL = os.getenv("MINIO_URL", "http://minio:9000") 
MINIO_CONSOLE_URL = "http://localhost:9001"
MLFLOW_URL = "http://localhost:5000"
AIRFLOW_URL = "http://localhost:8081"
ACCESS_KEY = "admin"
SECRET_KEY = "admin12345"
BUCKET_NAME = "market-data"
SILVER_PATH = "silver_layer_delta"

st.set_page_config(page_title="Ultimate DataFlow Terminal", layout="wide", page_icon="üèóÔ∏è")

st.markdown("""
    <style>
    .stApp { background-color: #0b0e14; color: #e1e4e8; }
    .metric-card { 
        background-color: #161b22; 
        padding: 20px; 
        border-radius: 12px; 
        border: 1px solid #30363d;
        text-align: center;
    }
    .status-online { color: #238636; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

def get_db_conn():
    return psycopg2.connect(host="postgres", database="market_db", user="admin", password="admin", port="5432")

def get_s3_fs():
    return s3fs.S3FileSystem(key=ACCESS_KEY, secret=SECRET_KEY, client_kwargs={'endpoint_url': MINIO_URL})

def add_indicators(df):
    if len(df) < 20: return df
    delta = df['average_price'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    df['RSI'] = 100 - (100 / (1 + (gain / loss)))
    df['MA20'] = df['average_price'].rolling(window=20).mean()
    df['std'] = df['average_price'].rolling(window=20).std()
    df['Upper'] = df['MA20'] + (df['std'] * 2)
    df['Lower'] = df['MA20'] - (df['std'] * 2)
    return df

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/8297/8297332.png", width=80)
    st.title("Admin Ops Center")
    
    st.markdown("### üîó Hƒ±zlƒ± Linkler")
    st.markdown(f"üìÇ [MinIO Console (9001)]({MINIO_CONSOLE_URL})")
    st.markdown(f"üß† [MLflow Tracking (5000)]({MLFLOW_URL})")
    st.markdown(f"‚öôÔ∏è [Airflow DAGs (8081)]({AIRFLOW_URL})")
    
    st.markdown("---")
    st.subheader("üõ†Ô∏è Pipeline Manuel Tetikleme")
    if st.button("üöÄ Spark ML Eƒüitimi Ba≈ülat"):
        os.system("docker exec spark-silver python train_model.py &")
        st.toast("MLflow Run Ba≈ülatƒ±ldƒ±!")
    
    if st.button("üíé dbt Gold Refresh"):
        os.system("docker exec dbt_transformer dbt run &")
        st.toast("PostgreSQL Tablolarƒ± G√ºncelleniyor...")

st.title("üöÄ Enterprise MLOps & Real-Time Lakehouse")

try:
    fs = get_s3_fs()
    files = fs.glob(f"s3://{BUCKET_NAME}/{SILVER_PATH}/**/*.parquet")
    df_raw = pd.concat([pd.read_parquet(fs.open(f)) for f in sorted(files)[-40:]])
    df_raw['processed_time'] = pd.to_datetime(df_raw['processed_time']) + pd.Timedelta(hours=3)
    df = add_indicators(df_raw.sort_values('processed_time'))
except:
    st.error("MinIO veya Spark verisi bulunamadƒ±. L√ºtfen sistemleri ba≈ülatƒ±n.")
    st.stop()

tab_realtime, tab_mlops, tab_gold, tab_infra = st.tabs([
    "üìà Canlƒ± Market & Teknik Analiz", "ü§ñ MLflow & Model Performansƒ±", "üèÜ dbt Gold Layer", "üìü Sistem Mimarisi & Saƒülƒ±k"
])

with tab_realtime:
    selected_sym = st.selectbox("Sembol Se√ßin", df['symbol'].unique())
    df_sub = df[df['symbol'] == selected_sym].tail(100)
    last = df_sub.iloc[-1]
    
    c1, c2, c3, c4 = st.columns(4)
    with c1: st.metric("Anlƒ±k Fiyat", f"${last['average_price']:,.2f}", f"{last['average_price']-df_sub.iloc[-2]['average_price']:.2f}")
    with c2: st.metric("AI Tahmini", f"${last['predicted_price']:,.2f}")
    with c3: st.metric("RSI (14)", f"{last.get('RSI', 0):.2f}")
    with c4: st.metric("Volatilite (Spark)", f"{last['volatility']:.6f}")

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=df_sub['processed_time'], y=df_sub['Upper'], name="Bollinger √úst", line=dict(color='rgba(255,255,255,0.1)')))
    fig.add_trace(go.Scatter(x=df_sub['processed_time'], y=df_sub['Lower'], name="Bollinger Alt", fill='tonexty', line=dict(color='rgba(255,255,255,0.1)')))
    fig.add_trace(go.Scatter(x=df_sub['processed_time'], y=df_sub['average_price'], name="Piyasa", line=dict(color='#1f77b4', width=3)))
    fig.add_trace(go.Scatter(x=df_sub['processed_time'], y=df_sub['predicted_price'], name="AI Tahmin", line=dict(dash='dot', color='#ff7f0e')))
    fig.update_layout(height=600, template="plotly_dark", title=f"{selected_sym} Detaylƒ± AI Analizi")
    st.plotly_chart(fig, use_container_width=True)

with tab_mlops:
    st.subheader("ü§ñ MLflow Model Tracking & Accuracy")
    df['Error'] = (df['average_price'] - df['predicted_price']).abs()
    
    col_a, col_b = st.columns(2)
    with col_a:
        st.write("#### Tahmin Doƒüruluƒüu (Regression Plot)")
        fig_acc = px.scatter(df, x="average_price", y="predicted_price", color="Error", trendline="ols")
        st.plotly_chart(fig_acc, use_container_width=True)
    with col_b:
        st.write("#### Hata Daƒüƒ±lƒ±mƒ± (Residual Analysis)")
        fig_err = px.histogram(df, x="Error", nbins=30, title="MAE Distribution")
        st.plotly_chart(fig_err, use_container_width=True)

with tab_gold:
    st.subheader("üèÜ dbt Analytics - PostgreSQL Gold Katmanƒ±")
    try:
        conn = get_db_conn()
        df_perf = pd.read_sql("SELECT * FROM fct_model_performance ORDER BY observation_hour DESC LIMIT 10", conn)
        df_summary = pd.read_sql("SELECT * FROM gold_market_summary LIMIT 10", conn)
        
        st.write("#### üìä Saatlik Performans (dbt fct_model_performance)")
        st.dataframe(df_perf, use_container_width=True)
        
        st.write("#### üí∞ Market √ñzeti (dbt gold_market_summary)")
        st.table(df_summary)
        conn.close()
    except:
        st.warning("dbt tablolarƒ± y√ºkleniyor... L√ºtfen Airflow √ºzerinden dbt job'ƒ±nƒ± kontrol edin.")

with tab_infra:
    st.subheader("üìü U√ßtan Uca Boru Hattƒ± ƒ∞zleme")
    
    i1, i2, i3 = st.columns(3)
    i1.metric("Sunucu CPU", f"%{psutil.cpu_percent()}")
    i2.metric("Sunucu RAM", f"%{psutil.virtual_memory().percent}")
    
    try:
        client = docker.from_env()
        containers = client.containers.list()
        i3.metric("Aktif Konteynerler", len(containers))
        
        st.write("#### üêã Docker Pipeline Durumu")
        c_data = [{"Servis": c.name, "Durum": c.status, "ƒ∞maj": c.image.tags[0] if c.image.tags else "N/A"} for c in containers]
        st.table(c_data)
    except:
        st.error("Docker Socket eri≈üimi yok!")

time.sleep(10)
st.rerun()
>>>>>>> cda2fd09ebf927cfc7e32d5c77b558c212d4f57c
